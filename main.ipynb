{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.data_cleaning import clean_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data into pandas DataFrame\n",
    "df = pd.read_csv('data/cyberbullying_tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get info about data\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename feature and label columns\n",
    "df = df.rename(columns={'tweet_text': 'tweet', 'cyberbullying_type': 'category'})\n",
    "\n",
    "# Remove duplicates\n",
    "df = df[~df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution for cyberbullying category\n",
    "category_counts = df['category'].value_counts()\n",
    "\n",
    "# Create a pie chart\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%', startangle=90, colors=['#66b3ff', '#99ff99', '#ffcc99', '#ff6666'])\n",
    "plt.title('Number of tweets for each category')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean tweets using functions defined in src, and drop duplicates\n",
    "# Define stop words for text cleaning\n",
    "stop_words = set(stopwords.words('english'))\n",
    "# Initialize lemmatizer for text cleaning\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "df['clean_tweet'] = [clean_tweet(tweet, lemmatizer, stop_words) for tweet in df['tweet']]\n",
    "df.drop_duplicates('clean_tweet', inplace=True)\n",
    "\n",
    "category_counts = df['category'].value_counts()\n",
    "\n",
    "# Create a pie chart\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.pie(category_counts, labels=category_counts.index, autopct='%1.1f%%', startangle=90, colors=['#66b3ff', '#99ff99', '#ffcc99', '#ff6666'])\n",
    "plt.title('Number of tweets for each category')\n",
    "plt.show()\n",
    "\n",
    "# After cleaning we can see that category \"other_cyberbullying\" is reduced to around 12%, because it is too generic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove \"other_cyberbullying category\" due to its incosistency and being too generic\n",
    "df = df[df['category'] != 'other_cyberbullying']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
